{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sanitizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parisman1/CognitiveDecline-NLP/blob/main/Sanitizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz28KrnJ9Y9D"
      },
      "source": [
        "# Drive mounting, pip installs, and imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t61_p1sBmDV-",
        "outputId": "93fdb330-9811-44e2-e16d-196c741e958c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0-GCKZumwqd"
      },
      "source": [
        "#/content/drive/MyDrive/CSCE 5215/Spring 2021/Shortened Enki Audio Files\n",
        "#/content/drive/MyDrive/CSCE 5215/Spring 2021/Shortened Enki Audio Files\n",
        "AudioPath = '/content/drive/MyDrive/CSCE 5215/Spring 2021/Shortened Enki Audio Files'\n",
        "BasePath = '/content/drive/MyDrive/CSCE 5215/Spring 2021'\n",
        "TestPath = '/content/drive/MyDrive/CSCE 5215/Spring 2021/AudioTestFolder'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYPyz49Pn2Hp"
      },
      "source": [
        "!pip install pyAudioAnalysis\n",
        "!pip install eyed3\n",
        "!pip install pydub\n",
        "!pip install hmmlearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvSDdzXTT7JH"
      },
      "source": [
        "# for data ingestion\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from math import ceil\n",
        "\n",
        "# for data exploration\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for basic modeling (sklearn)\n",
        "import sklearn as sk\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score, fbeta_score, confusion_matrix, make_scorer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score, cross_validate, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaB3zZZbrPRJ"
      },
      "source": [
        "import hmmlearn.hmm\n",
        "from pydub import AudioSegment\n",
        "import eyed3\n",
        "import pyAudioAnalysis as pAA\n",
        "from pyAudioAnalysis import audioBasicIO\n",
        "from pyAudioAnalysis import ShortTermFeatures\n",
        "from pyAudioAnalysis import audioSegmentation as aS\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlH-PvCT9ljB"
      },
      "source": [
        "# pyAudioAnalysis testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7CTLxXAyF2D"
      },
      "source": [
        "os.chdir(AudioPath)\n",
        "#os.getcwd()\n",
        "myPath = os.getcwd()\n",
        "myPath += '/'\n",
        "entries = Path(myPath)\n",
        "name = []\n",
        "for index in entries.iterdir():\n",
        "  name.append(index.name)\n",
        "\n",
        "print(myPath + name[0])\n",
        "#for index in range(10):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf1h8llvQmaQ"
      },
      "source": [
        "def display_plot(F, index, f_names):\n",
        "  plt.plot(F[index,:])\n",
        "  plt.xlabel('Frame no')\n",
        "  plt.ylabel(f_names[index]) \n",
        "  plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUi_TIyo9nE9"
      },
      "source": [
        "index = 0\n",
        "[Fs, x] = audioBasicIO.read_audio_file(myPath + name[0])\n",
        "F, f_names = ShortTermFeatures.feature_extraction(x[:, 0], Fs, 0.050*Fs, 0.025*Fs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rldNI8EoH95P"
      },
      "source": [
        "for n in name:\n",
        "  print(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPC4ObNSR1Ng"
      },
      "source": [
        "tempdf = pd.DataFrame()\n",
        "ShortTermFeaturesList = []\n",
        "index = 0\n",
        "for n in name:\n",
        "  [Fs, x] = audioBasicIO.read_audio_file(myPath + n)\n",
        "  F, f_names = ShortTermFeatures.feature_extraction(x[:, 0], Fs, 0.050*Fs, 0.025*Fs)\n",
        "  tempdf['window'] = index\n",
        "  tempdf['energy'] = F[0]\n",
        "  ShortTermFeaturesList.append(tempdf)\n",
        "  tempdf = pd.DataFrame()\n",
        "  index += 1\n",
        "\n",
        "\n",
        "'''\n",
        "Tempdf = pd.DataFrame()\n",
        "FeatureList = []\n",
        "for index, file in enumerate(MTF):\n",
        "  Tempdf['name'] = MidFN\n",
        "  Tempdf['#'] = MTF[index]\n",
        "  FeatureList.append(Tempdf)\n",
        "  Tempdf = pd.DataFrame()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2regwnSBUZ"
      },
      "source": [
        "sum = 0\n",
        "for data in F[0]:\n",
        "  sum += data\n",
        "data = data / len(x)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j25kkp94HyqA"
      },
      "source": [
        "pd.options.display.max_rows = 500\n",
        "ShortTermFeaturesList[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb6qlhpat5j_"
      },
      "source": [
        "display_plot(F, 0, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es1hm_uMjk0x"
      },
      "source": [
        "display_plot(F, 1, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7LHhrYotmwq"
      },
      "source": [
        "display_plot(F, 2, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3WMHwQittzA"
      },
      "source": [
        "display_plot(F, 3, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp2IkRJ0t0DH"
      },
      "source": [
        "display_plot(F, 4, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXJwvPz0t2eH"
      },
      "source": [
        "display_plot(F, 5, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAgTBtKp1suD"
      },
      "source": [
        "display_plot(F, 6, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkrug8uu10CL"
      },
      "source": [
        "display_plot(F, 7, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS7uHlKj12Jn"
      },
      "source": [
        "display_plot(F, 8, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzerohPl15tg"
      },
      "source": [
        "display_plot(F, 9, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8V2vJeL4O2c"
      },
      "source": [
        "display_plot(F, 10, f_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2mQO6Tq99m2"
      },
      "source": [
        "# Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQKg7si6GOjK"
      },
      "source": [
        "MTF, List, MidFN = pAA.MidTermFeatures.directory_feature_extraction(TestPath, 1.0, 1.0, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzIyWZo9qWNG"
      },
      "source": [
        "MTF[0]\n",
        "#len(MTF[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaJxLBeEZYC5"
      },
      "source": [
        "# Actual Feature Extraction Cells\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRwPMYk01XFZ"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/CSCE 5215/Spring 2021/Shortened Enki Audio Files (1)')\n",
        "#os.getcwd()\n",
        "myPath = os.getcwd()\n",
        "myPath += '/'\n",
        "entries = Path(myPath)\n",
        "name = []\n",
        "for index in entries.iterdir():\n",
        "  name.append(index.name)\n",
        "\n",
        "print(myPath + name[0])\n",
        "print(len(name))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZUdi-qr2PxN"
      },
      "source": [
        "MTF, List, MidFN = pAA.MidTermFeatures.directory_feature_extraction('/content/drive/MyDrive/CSCE 5215/Spring 2021/Shortened Enki Audio Files (1)', 1.0, 1.0, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFtVeohASM-g"
      },
      "source": [
        "Tempdf = pd.DataFrame()\n",
        "FeatureList = []\n",
        "templist = []\n",
        "for index, file in enumerate(MTF):\n",
        "  MTFlist = MTF[index].tolist()\n",
        "  MTFlist.insert(0, name[index])\n",
        "  FeatureList.append(MTFlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqMW5SGsSsbK"
      },
      "source": [
        "for i in range(len(FeatureList)):\n",
        "  FeatureList[i] = FeatureList[i][: len(FeatureList[i]) - 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omn6y8XHKHWB"
      },
      "source": [
        "FeatureList[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZfGyY5AaVHH"
      },
      "source": [
        "with open('/content/drive/MyDrive/CSCE 5215/Spring 2021/ProjectDat.csv', 'r', newline='') as cfile:\n",
        "  fin = csv.reader(cfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  for row in fin:\n",
        "    Names = row\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYmlm6SxabYJ"
      },
      "source": [
        "Names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZl8TUQh2Qyb"
      },
      "source": [
        "with open('/content/drive/MyDrive/CSCE 5215/Spring 2021/ProjectDat.csv', 'w', newline='') as cfile:\n",
        "  fout = csv.writer(cfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  fout.writerow(Names)\n",
        "  fout.writerows(FeatureList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQvuUMMkEiD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCyYSbugkp7O"
      },
      "source": [
        "# Load CSV into pd dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghc8T5dEtgNY"
      },
      "source": [
        "Data['file_name'] = [\n",
        "  re.match('^[0-9]*[a-zA-z]*(_|\\s|-|[0-9])', sub).group(0)[:-1]\n",
        "  for sub in Data['file_name']\n",
        "]\n",
        "\n",
        "# HERE IS THE THING\n",
        "# df = pd.merge(label_df, spss_df, left_on='Subject ID', right_on='participant_id')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvqPOILorlNm"
      },
      "source": [
        "final_path = '/content/drive/MyDrive/CSCE 5215/Spring 2021/final_pred.csv'\n",
        "data_path = '/content/drive/MyDrive/CSCE 5215/Spring 2021/ProjectDat.csv'\n",
        "target_data = '/content/drive/MyDrive/CSCE 5215/Spring 2021/Projet_Target.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b-xLL0trpES"
      },
      "source": [
        "pd.options.display.max_rows = 200\n",
        "pd.options.display.max_columns = 200"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6E-ndUckv76"
      },
      "source": [
        "pred = pd.read_csv(final_path)\n",
        "Data = pd.read_csv(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twcg4hWytvoF"
      },
      "source": [
        "Data = Data.sort_values(['file_name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pIIyjOiwvrb"
      },
      "source": [
        "Data['file_name'] = Data['file_name'].str.split(' ').str[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fxLDfKuxanQ"
      },
      "source": [
        "Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUreOedMruMV"
      },
      "source": [
        "pred = pred[~pred['final'].isin(['-'])]\n",
        "pred = pred.sort_values(\"Subject ID\")\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLRA4hhqta4Z"
      },
      "source": [
        "Data[\"Target\"] = pred[\"final\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-VJXUlL1Jrd"
      },
      "source": [
        "Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVBl-TXIlWC0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DON_h5qcf5eS"
      },
      "source": [
        "Data.to_csv(target_data, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp5MOyp0DLeh"
      },
      "source": [
        "big_path = '/content/drive/MyDrive/CSCE 5215/Spring 2021/T.csv'\n",
        "jsons = pd.read_csv(big_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gs6mGKWESSN"
      },
      "source": [
        "jsons = jsons.sort_values(['file_name'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDVoa9UwEYvy"
      },
      "source": [
        "jsons.to_csv('/content/drive/MyDrive/CSCE 5215/Spring 2021/Projet_Target_2.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOD7MHO9FXHW"
      },
      "source": [
        "final_path = '/content/drive/MyDrive/CSCE 5215/Spring 2021/FINAL_V2.csv'\n",
        "final = pd.read_csv(final_path)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH569LYgGEBE"
      },
      "source": [
        "final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596GxpaojaoE"
      },
      "source": [
        "# Basic Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8s7SjxzAUL"
      },
      "source": [
        "pd.options.display.max_rows = 200\n",
        "pd.options.display.max_columns = 14"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mvNLhUMkd-9"
      },
      "source": [
        "Data = Data.dropna(subset =['Target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1jNtlfGmSTo"
      },
      "source": [
        "Data = Data.dropna(axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yU7brIGjdf5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression,LinearRegression,Perceptron\n",
        "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
        "from sklearn.preprocessing import normalize\n",
        "import math\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYnJS4kmc2J"
      },
      "source": [
        "train_data = final.sample(frac=0.8, random_state=0)\n",
        "test_data = final.drop(train_data.index)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynNqiDm5mpjV"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Yhw20zmvEM"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiqmX9Lzm3Rt"
      },
      "source": [
        "train_feature = train_data.copy()\n",
        "test_feature = test_data.copy()\n",
        "\n",
        "train_label = train_feature.pop('Target')\n",
        "test_label = test_feature.pop('Target')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzTz6keApjlm"
      },
      "source": [
        "train_feature = train_feature.drop('file_name', axis='columns')\n",
        "test_feature = test_feature.drop('file_name', axis='columns')\n",
        "\n",
        "train_feature = train_feature.drop('Unnamed: 0', axis='columns')\n",
        "test_feature = test_feature.drop('Unnamed: 0', axis='columns')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Occa9Fnobg"
      },
      "source": [
        "Testing = train_feature.describe().transpose()[['mean', 'std']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StzFkDZMpLR3"
      },
      "source": [
        "train_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WktJxIyvnO2J"
      },
      "source": [
        "test_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaENLk6OzWh_"
      },
      "source": [
        "train_feature.reset_index(drop=True, inplace=True)\n",
        "train_label.reset_index(drop=True, inplace=True)\n",
        "test_feature.reset_index(drop=True, inplace=True)\n",
        "test_label.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09YmcfL0srt5"
      },
      "source": [
        "def accuracy(predictions,labels):\n",
        "    if (len(predictions) != len(labels)):\n",
        "        print(\"they are not equel\")\n",
        "        return 0\n",
        "    counter=0\n",
        "    for i in range(len(labels)):\n",
        "        if (predictions[i] == labels[i]):\n",
        "            counter+=1\n",
        "    return counter/len(labels)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "408jK7QGvtjR"
      },
      "source": [
        "data_normed = sklearn.preprocessing.normalize(train_feature, norm='l2')\n",
        "print(data_normed.shape)\n",
        "test_norm = sklearn.preprocessing.normalize(test_feature, norm='l2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi8qPXb_wxVp"
      },
      "source": [
        "print(train_feature.shape)\n",
        "print(test_label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJnCYm6SwUct"
      },
      "source": [
        "len(data_normed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq3UhFfPr-oS"
      },
      "source": [
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(train_feature, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om4uDzlbsVTb"
      },
      "source": [
        "preds = clf.predict(test_feature)\n",
        "accuracy(preds, test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vie6UZDLuyVH"
      },
      "source": [
        "len(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0SQHB_TtBAn"
      },
      "source": [
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zed4vqcfVRjk"
      },
      "source": [
        "clf = sklearn.tree.DecisionTreeClassifier()\n",
        "clf.fit(data_normed, train_label)\n",
        "preds = clf.predict(test_norm)\n",
        "accuracy(preds, test_label.to_numpy())\n",
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktL_eDB-QkSE"
      },
      "source": [
        "clf = sklearn.tree.DecisionTreeClassifier()\n",
        "clf.fit(train_feature, train_label)\n",
        "preds = clf.predict(test_feature)\n",
        "accuracy(preds, test_label.to_numpy())\n",
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaOMMtQyV_N3"
      },
      "source": [
        "clf = sklearn.ensemble.RandomForestClassifier(max_depth=100000)\n",
        "clf.fit(data_normed, train_label)\n",
        "preds = clf.predict(test_norm)\n",
        "accuracy(preds, test_label.to_numpy())\n",
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDEIlsfSRB3d"
      },
      "source": [
        "clf = sklearn.ensemble.RandomForestClassifier(max_depth=100000)\n",
        "clf.fit(train_feature, train_label)\n",
        "preds = clf.predict(test_feature)\n",
        "print(accuracy(preds, test_label.to_numpy()))\n",
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouDrDi6WRowH"
      },
      "source": [
        "clf = sklearn.svm.SVC()\n",
        "clf.fit(train_feature, train_label)\n",
        "preds = clf.predict(test_feature)\n",
        "print(accuracy(preds, test_label.to_numpy()))\n",
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_FLyiEMSED5"
      },
      "source": [
        "clf = sklearn.svm.LinearSVC()\n",
        "clf.fit(train_feature, train_label)\n",
        "preds = clf.predict(test_feature)\n",
        "print(accuracy(preds, test_label.to_numpy()))\n",
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgGRY9s9TPVT"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i_4uR_ISPkq"
      },
      "source": [
        "clf = GaussianNB()\n",
        "clf.fit(train_feature, train_label)\n",
        "preds = clf.predict(test_feature)\n",
        "print(accuracy(preds, test_label.to_numpy()))\n",
        "print(classification_report(y_pred = preds, y_true = test_label.to_numpy()))\n",
        "print('======')\n",
        "print(preds)\n",
        "print('======')\n",
        "print(test_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seqg6EPgUm-d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnhmb6oEYJTz"
      },
      "source": [
        "slimBoi = final.iloc[:,138:]"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRgABn6KY4lE"
      },
      "source": [
        "slimBoi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teHoeQc_Ztxz"
      },
      "source": [
        "def classist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogzrctHqUmvj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnxVOsoVpRgi"
      },
      "source": [
        "norm = preprocessing.Normalization()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27uCAQ0IpWXO"
      },
      "source": [
        "norm.adapt(np.array(train_feature))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYzCVpQakHUI"
      },
      "source": [
        "linear_model = tf.keras.Sequential([\n",
        "    train_feature,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GepcsdDljcyB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-dlOCw4Q5QV"
      },
      "source": [
        "# Testing Simple models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGJUf5d3Q93F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJImYzXIah9o"
      },
      "source": [
        "# older work on extraction, keeping for keeps sake\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dM2Jmb3OSp6"
      },
      "source": [
        "# so this is a problem because it is saying each file has the same \"features\"\n",
        "for index, sound in enumerate(MTF):\n",
        "  if index != 6:\n",
        "    if np.array_equal(MTF[index], MTF[index+1]):\n",
        "    #if MTF[index].all() == MTF[index+1].all():\n",
        "      print('OOF')\n",
        "    else:\n",
        "      print(MTF[index]-MTF[index+1])\n",
        "      print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-gBsskbPEbY"
      },
      "source": [
        "# this is making sure the two lists are the same size, if they are not then it adds blank data to make them the same size\n",
        "for i in range(0,7):\n",
        "  if len(MTF[i]) > len(MidFN):\n",
        "    for _ in range(0, (len(MTF[i]) - len(MidFN))):\n",
        "      MidFN.append('Null')\n",
        "    len(MidFN)\n",
        "\n",
        "  elif len(MTF[i]) < len(MidFN):\n",
        "    for index, sound in enumerate(MTF):\n",
        "      for _ in range(0, (len(MidFN[i]) - len(MTF))):\n",
        "        sound[index].append(0)\n",
        "\n",
        "  len(MTF[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShKyvLyitQW0"
      },
      "source": [
        "for i in MTF:\n",
        "  print(len(i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNB1BTVpP7C4"
      },
      "source": [
        "print('MTF: ',len(MTF[1]))\n",
        "print('MidFN ',len(MidFN))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZAWyX6QU4cG"
      },
      "source": [
        "MTF, signal, List = pAA.MidTermFeatures.directory_feature_extraction_no_avg(TestPath, 1.0, 1.0, 0.5, 0.5)\n",
        "print('MTF: ',len(MTF))\n",
        "print('signal ',len(signal))\n",
        "no_avgdf = pd.DataFrame()\n",
        "no_avgdf['1'] = MTF\n",
        "no_avgdf['2'] = signal\n",
        "no_avgdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwp6mvTi8jTM"
      },
      "source": [
        "signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO4ntQORsKAv"
      },
      "source": [
        "MTF[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQoE9vIo-YfA"
      },
      "source": [
        "# Hidden Marcov Chain attempt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLBj_UaE86dk"
      },
      "source": [
        "#FROM AUDIOSEGMENTATION\n",
        "def train_hmm_from_directory(folder_path, hmm_model_name, mid_window, mid_step):\n",
        "    \"\"\"\n",
        "    This function trains a HMM model for segmentation-classification using\n",
        "    a where WAV files and .segment (ground-truth files) are stored\n",
        "    ARGUMENTS:\n",
        "     - folder_path:     the path of the data diretory\n",
        "     - hmm_model_name:  the name of the HMM model to be stored\n",
        "     - mt_win:          mid-term window size\n",
        "     - mt_step:         mid-term window step\n",
        "    RETURNS:\n",
        "     - hmm:            an object to the resulting HMM\n",
        "     - class_names:    a list of class_names\n",
        "\n",
        "    After training, hmm, class_names, along with the mt_win\n",
        "    and mt_step values are stored in the hmm_model_name file\n",
        "    \"\"\"\n",
        "    f_all = 0\n",
        "    flags_all = np.array([])\n",
        "    class_names_all = []\n",
        "    for i, f in enumerate(glob.glob(folder_path + os.sep + '*.wav')):\n",
        "        # for each WAV file\n",
        "        wav_file = f\n",
        "        gt_file = f.replace('.wav', '.segments')\n",
        "        if os.path.isfile(gt_file):\n",
        "            seg_start, seg_end, seg_labs = read_segmentation_gt(gt_file)\n",
        "            flags, class_names = \\\n",
        "                segments_to_labels(seg_start, seg_end, seg_labs, mid_step)\n",
        "            for c in class_names:\n",
        "                # update class names:\n",
        "                if c not in class_names_all:\n",
        "                    class_names_all.append(c)\n",
        "            sampling_rate, signal = audioBasicIO.read_audio_file(wav_file)\n",
        "            feature_vector, _, _ = \\\n",
        "                mtf.mid_feature_extraction(signal, sampling_rate,\n",
        "                                           mid_window * sampling_rate,\n",
        "                                           mid_step * sampling_rate,\n",
        "                                           round(sampling_rate * 0.050),\n",
        "                                           round(sampling_rate * 0.050))\n",
        "\n",
        "            flag_len = len(flags)\n",
        "            feat_cols = feature_vector.shape[1]\n",
        "            min_sm = min(feat_cols, flag_len)\n",
        "            feature_vector = feature_vector[:, 0:min_sm]\n",
        "            flags = flags[0:min_sm]\n",
        "\n",
        "            flags_new = []\n",
        "            # append features and labels\n",
        "            for j, fl in enumerate(flags):\n",
        "                flags_new.append(class_names_all.index(class_names_all[flags[j]]))\n",
        "\n",
        "            flags_all = np.append(flags_all, np.array(flags_new))\n",
        "\n",
        "            if i == 0:\n",
        "                f_all = feature_vector\n",
        "            else:\n",
        "                f_all = np.concatenate((f_all, feature_vector), axis=1)\n",
        "\n",
        "    # compute HMM statistics\n",
        "    class_priors, transmutation_matrix, means, cov = \\\n",
        "        train_hmm_compute_statistics(f_all, flags_all)\n",
        "    # train the HMM\n",
        "    hmm = hmmlearn.hmm.GaussianHMM(class_priors.shape[0], \"diag\")\n",
        "    hmm.covars_ = cov\n",
        "    hmm.means_ = means\n",
        "    hmm.startprob_ = class_priors\n",
        "    hmm.transmat_ = transmutation_matrix\n",
        "\n",
        "    save_hmm(hmm_model_name, hmm, class_names_all, mid_window, mid_step)\n",
        "\n",
        "    return hmm, class_names_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC3OkG20--nq"
      },
      "source": [
        "#aS.train_hmm_from_directory\n",
        "train_hmm_from_directory(myPath, 'hmm1', 1.0, 1.0)\n",
        "aS.hmm_segmentation(myPath + name[0], 'hmm1', True, BasePath/Test.segments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIh3GiqTXqJv"
      },
      "source": [
        "### **AUDIO DIARIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iej9tdh1S_on"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oae9uKsokNYe"
      },
      "source": [
        "# Audio & text Sync\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpZmvp9fkT4Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxY5f9tOg4B1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4u063LAhHGy",
        "outputId": "41367f81-25b1-4c51-bfa2-20f2b0f42ea8"
      },
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: as in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: sr in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.24.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "Plu78zNcg3up",
        "outputId": "d6ccb31c-d0ca-4634-8b54-e964c92b448b"
      },
      "source": [
        "\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import speech_recognition as sr\n",
        "\n",
        "# create a speech recognition object\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# a function that splits the audio file into chunks\n",
        "# and applies speech recognition\n",
        "path='/content/drive/MyDrive/CSCE 5215/Spring 2021/Shortened Enki Audio Files/1CCC 2-19-18.wav'\n",
        "\n",
        "\n",
        "\n",
        "def get_large_audio_transcription(path):\n",
        "    \"\"\"\n",
        "    Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\n",
        "    \"\"\"\n",
        "    # open the audio file using pydub\n",
        "    sound = AudioSegment.from_wav(path)\n",
        "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
        "    chunks = split_on_silence(sound,\n",
        "        # experiment with this value for your target audio file\n",
        "        min_silence_len = 900,\n",
        "        # adjust this per requirement\n",
        "        silence_thresh = sound.dBFS - 14,\n",
        "        # keep the silence for 1 second, adjustable as well\n",
        "        keep_silence = 900,\n",
        ")\n",
        "    folder_name = \"audio-chunks\"\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    # process each chunk\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        # recognize the chunk\n",
        "        with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_listened = r.record(source)\n",
        "            # try converting it to text\n",
        "            try:\n",
        "                text = r.recognize_google(audio_listened)\n",
        "            except sr.UnknownValueError as e:\n",
        "                print(\"Error:\", str(e))\n",
        "            else:\n",
        "                text = f\"{text.capitalize()}. \"\n",
        "                print(chunk_filename, \":\", text)\n",
        "                whole_text += text\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text\n",
        "\n",
        "get_large_audio_transcription(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a913be49f73a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwhole_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mget_large_audio_transcription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-a913be49f73a>\u001b[0m in \u001b[0;36mget_large_audio_transcription\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# open the audio file using pydub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# split audio sound where silence is 700 miliseconds or more and get chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     chunks = split_on_silence(sound,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_wav\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydub/utils.py\u001b[0m in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mclose_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CSCE 5215/Spring 2021/Shortened Enki Audio Files/1CCC 2-19-18.wav'"
          ]
        }
      ]
    }
  ]
}